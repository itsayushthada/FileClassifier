{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "L&T",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "iG2tvgGZRejV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "KPshNC-gRhpw",
        "colab_type": "code",
        "outputId": "1e523b10-e615-4ee8-d63c-204d6fbe87dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "r8av_kqBRko4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "root_path = \"/content/drive/My Drive/Backend/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iu-iFDFnxvGx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Information"
      ]
    },
    {
      "metadata": {
        "id": "IqAyGzQyLKX3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-hwzoOlDYAlT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_data():\n",
        "    filename = []\n",
        "    type = []\n",
        "\n",
        "    for x in list(os.walk(root_path+\"Files/\"))[0][-1]:\n",
        "        filename.append(x)\n",
        "        type.append(x.split(\".\")[-1].lower())\n",
        "\n",
        "    print(Counter(type))\n",
        "    idx = list(range(0,len(filename)))\n",
        "    \n",
        "    filename = np.array(filename)\n",
        "    type = np.array(type)\n",
        "    \n",
        "    np.random.shuffle(idx)\n",
        "    filename = filename[idx]\n",
        "    type = type[idx]\n",
        "\n",
        "    return filename, type"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tj6GZ6DKhjzu",
        "colab_type": "code",
        "outputId": "aa9e0da6-a3d9-449a-e6a0-59e9bf27c930",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "t, u = get_data()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'docx': 224, 'pdf': 182, 'doc': 169, 'jpg': 147, 'sldprt': 143, 'csv': 136, 'png': 117, 'cbr': 94, 'a': 78, 'pptx': 60, 'ppt': 24, 'sldasm': 19, 'gif': 2, 'slddrt': 1, 'slddrw': 1, 'jpeg': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YR7Q6i34SPtQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Text Processing"
      ]
    },
    {
      "metadata": {
        "id": "D6vsBrjVSOvk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8oia1L58Sjj5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def feature_extractor(filename):\n",
        "    string = \"\"  \n",
        "    with open(filename, \"rb\") as file:\n",
        "        string = str(\"{0:b}\".format(int.from_bytes(file.read(), byteorder='big')))\n",
        "    file.close()\n",
        "    \n",
        "    return list(map(lambda x:int(x,2), textwrap.wrap(string, 12))), (filename.split(\".\")[-1]).lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BKtT2n-dSlRx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def data_sampler(data_array, samples, min_sample_size, max_sample_size, p_update):\n",
        "    \n",
        "    theta1 = p_update[\"theta1\"] + len(data_array)//2\n",
        "    theta2 = p_update[\"theta2\"] + len(data_array)//10\n",
        "    \n",
        "    indices = np.random.normal(loc = theta1, \n",
        "                               scale = theta2, \n",
        "                               size = (samples,1)).astype(np.int32)\n",
        "    \n",
        "    phi1 = p_update[\"phi1\"] + (min_sample_size + max_sample_size)//2\n",
        "    phi2 = p_update[\"phi2\"] + np.ceil((max_sample_size - min_sample_size)/np.sqrt(samples))\n",
        "    \n",
        "    sizes = np.clip(np.random.normal(loc = phi1, \n",
        "                             scale = phi2, \n",
        "                             size = (samples,1)).astype(np.int32), min_sample_size, max_sample_size)\n",
        "    \n",
        "    param = {\n",
        "                \"theta1\": theta1, \n",
        "                \"theta2\": theta2,\n",
        "                \"phi1\": min_sample_size,\n",
        "                \"phi2\": max_sample_size,\n",
        "                \"dist1\": \"normal\",\n",
        "                \"dist2\": \"normal\"\n",
        "            }\n",
        "    \n",
        "    return list(map(lambda st,sz: data_array[st[0]:st[0]+sz[0]], indices,sizes)), param"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hnsBAgtVSoQc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def padding(samples, max_sample_length):\n",
        "    return list(map(lambda x: np.array((x+[0]*(max_sample_length-len(x)))[:max_sample_length]), samples))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0WwwwdN6wmLu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_data(file_list, type_list, n_samples, min_sample_length, max_sample_length, p_update):\n",
        "    data, type = [], []\n",
        "\n",
        "    for i in range(len(file_list)):\n",
        "        data_arr = feature_extractor(root_path + \"Files/\"+ file_list[i])\n",
        "        feat = data_sampler(data_arr[0], n_samples, min_sample_length, max_sample_length, p_update)\n",
        "\n",
        "        data = data + padding(feat[0], max_sample_length)\n",
        "        type = type+ [file_type_dict[type_list[i]]]*n_samples\n",
        "\n",
        "    data = np.array(data)\n",
        "    type = np.array(type)\n",
        "\n",
        "    t = np.array(range(0,len(file_list)*n_samples))\n",
        "    np.random.shuffle(t)\n",
        "\n",
        "    return data[t], type[t], feat[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y9KD-MnEWFNY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8f2dbc6-649b-4638-d500-6f21fb674ce6"
      },
      "cell_type": "code",
      "source": [
        "for x in [[6,4,3]]:\n",
        "    print(np.array((x+[0]*(6-len(x)))))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6 4 3 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OamL8BgBS2Co",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Modelling"
      ]
    },
    {
      "metadata": {
        "id": "4wLkLf3MSq8h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Layer\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer,Conv1D,GRU,Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7x3me_cWTZnI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MeanLayer(Layer):\n",
        "\n",
        "    \"\"\" Identity transform layer that Flatten the result of Conv1D Layer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        self.is_placeholder = True\n",
        "        super(MeanLayer, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        kl_batch = K.sqrt(K.mean(K.square(inputs), axis=-1))\n",
        "        self.add_loss(K.mean(K.reshape(kl_batch, (kl_batch.shape[0], -1)), axis=-1) , inputs=kl_batch)\n",
        "        return kl_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ub2ke3QkTi1A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Time_steps=100\n",
        "feature_length=4096\n",
        "num_of_classes=10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OqU_XRV0Tjat",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(InputLayer(input_shape=(Time_steps, feature_length), batch_size=8))\n",
        "\n",
        "model.add(GRU(Time_steps,return_sequences=True))\n",
        "model.add(GRU(Time_steps,return_sequences=True))\n",
        "\n",
        "model.add(Conv1D(filters=100, kernel_size=32))\n",
        "model.add(Conv1D(filters=50, kernel_size=32))\n",
        "\n",
        "model.add(MeanLayer())\n",
        "\n",
        "model.add(Dense(16))\n",
        "model.add(Dense(num_of_classes, activation=\"sigmoid\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r9BJ65hsTyH-",
        "colab_type": "code",
        "outputId": "352a13ec-2cc3-48c2-d1bc-f334b8f4ff1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_4 (GRU)                  (8, 100, 100)             1259100   \n",
            "_________________________________________________________________\n",
            "gru_5 (GRU)                  (8, 100, 100)             60300     \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (8, 69, 100)              320100    \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (8, 38, 50)               160050    \n",
            "_________________________________________________________________\n",
            "mean_layer_2 (MeanLayer)     (8, 38)                   0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (8, 16)                   624       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (8, 10)                   170       \n",
            "=================================================================\n",
            "Total params: 1,800,344\n",
            "Trainable params: 1,800,344\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "glN-zECjWrnS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Feathure Defination"
      ]
    },
    {
      "metadata": {
        "id": "WGbek5gOW_Li",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "min_sample_length = 50\n",
        "max_sample_length = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tmt8Ccatl5cO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_type_dict = {\n",
        "    'docx': 0, \n",
        "    'pdf': 1, \n",
        "    'doc': 2, \n",
        "    'jpg': 3,\n",
        "    'gif': 3, \n",
        "    'jpeg': 3, \n",
        "    'sldprt': 4,\n",
        "    'slddrt': 4, \n",
        "    'slddrw': 4,\n",
        "    'sldasm': 4,\n",
        "    'csv': 5, \n",
        "    'png': 6, \n",
        "    'cbr': 7, \n",
        "    'a': 8, \n",
        "    'pptx': 9, \n",
        "    'ppt': 9\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gQIvLd6-yIIG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p_update = {\n",
        "    \"theta1\": 0,\n",
        "    \"theta2\": 0,\n",
        "    \"phi1\": 0,\n",
        "    \"phi2\": 0\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2xSwvpytx743",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "cost = 1e12\n",
        "param = 0\n",
        "model_copy = model\n",
        "name = -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qjw9HRHM3Z_U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model1=model\n",
        "model1.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "byfE-h1kAYu2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training"
      ]
    },
    {
      "metadata": {
        "id": "tkLCN5_R1nq0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2J1G1M58zrOZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mdir = list(os.walk(root_path+\"Model/\"))[0][-1]\n",
        "if len(mdir) != 0:\n",
        "    model = load_model(\"{}Model/{}.h5\".format(root_path, name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e6xWJ-5VZC8p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    for i in range(0,len(t),10):\n",
        "        datax, typex, param = model_data(\n",
        "                                          file_list = t[i:min(i+10, len(t))],\n",
        "                                          type_list = u[i:min(i+10, len(t))],\n",
        "                                          n_samples = 20,\n",
        "                                          min_sample_length = min_sample_length,\n",
        "                                          max_sample_length = max_sample_length,\n",
        "                                          p_update = p_update)\n",
        "        x_data = []\n",
        "\n",
        "        for i in range(datax.shape[0]):\n",
        "            x_data.append(np.eye(4096)[datax[i].astype(np.int32)])\n",
        "\n",
        "        x_data = np.array(x_data)\n",
        "        y_data = np.eye(num_of_classes)[typex]\n",
        "        model_copy.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "        m=model_copy.fit(x_data,y_data)\n",
        "        d=m.history[\"loss\"]\n",
        "        cc_loss=(d[0][0]+d[0][1]+d[0][2]+d[0][3])/4\n",
        "\n",
        "        if cc_loss < cost:\n",
        "            cost = cc_loss\n",
        "            model = tf.keras.models.clone_model(\n",
        "                    model_copy,\n",
        "                    input_tensors=None\n",
        "                    )\n",
        "\n",
        "            model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "            model.set_weights(model_copy.get_weights())\n",
        "            p_update = {\n",
        "                          \"theta1\": np.random.randint(-10, 11),\n",
        "                          \"theta2\": np.random.randint(-50, 51),\n",
        "                          \"phi1\": np.random.randint(-5, 6),\n",
        "                          \"phi2\": np.random.randint(-5, 6)\n",
        "                          }\n",
        "\n",
        "        if i%50==0 and i!=0:\n",
        "            print(i, \"Model Saved.....\\n\\n\\n\")\n",
        "            model.save(root_path + '/Model/my_model{}.h5'.format((name + 1)%5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Op4eb7i920RX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Last Saved Model was {}\".format(name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yK9FMhmgasG6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Test Section"
      ]
    },
    {
      "metadata": {
        "id": "u3z_oyria872",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sdnkgslvnasnvoin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kW557Toia2LR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "name = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kjgc-n4EarkK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = load_model(\"{}Model/{}.h5\".format(root_path, name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kvYyLTzvQQt_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model.predict ca be used with samples"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}